{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6772390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683de27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.read_parquet('ThermocoupleData_2024-12_v2.parquet')\n",
    "df1 = pd.read_parquet('ThermocoupleData_2025-01_v2.parquet')\n",
    "df2 = pd.read_parquet('ThermocoupleData_2025-02_v2.parquet')\n",
    "df3 = pd.read_parquet('ThermocoupleData_2025-03_v2.parquet')\n",
    "df4 = pd.read_parquet('ThermocoupleData_2025-04_v2.parquet')\n",
    "\n",
    "dfall = pd.concat([df12, df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5277f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df12: 44641\n",
      "df1: 44641\n",
      "df2: 40321\n",
      "df3: 44581\n",
      "df4: 33121\n",
      "dfall: 207305\n"
     ]
    }
   ],
   "source": [
    "# count of all the df rows\n",
    "print(f\"df12: {len(df12)}\")\n",
    "print(f\"df1: {len(df1)}\")\n",
    "print(f\"df2: {len(df2)}\")\n",
    "print(f\"df3: {len(df3)}\")\n",
    "print(f\"df4: {len(df4)}\")\n",
    "print(f\"dfall: {len(dfall)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20288cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateTime', 'AvgTemp_ZON1_M', 'AvgTemp_ZON2_M', 'AvgTemp_ZON3_M',\n",
       "       'AvgTemp_ZON4_M', 'AvgTemp_ZON5_M', 'AvgTemp_ZON6_M',\n",
       "       'LineControlHastSverk4_1Act', 'UgnZon1BransleFlodeAr_Over',\n",
       "       'UgnZon1BransleFlodeAr_Under', 'UgnZon1OljaFlodeAr_FT131',\n",
       "       'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
       "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4',\n",
       "       'UgnZon2BransleFlodeAr_Over', 'UgnZon2BransleFlodeAr_Under',\n",
       "       'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1',\n",
       "       'UgnZon2TempSkyddAr_TC2', 'UgnZon2TempVaggOverBandAr_TC3',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4', 'UgnZon3BransleFlodeAr_Over',\n",
       "       'UgnZon3BransleFlodeAr_Under', 'UgnZon3OljaFlodeAr_FT331',\n",
       "       'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
       "       'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', 'UgnZon3Temp_TC5_Ar',\n",
       "       'UgnZon4BransleFlodeAr_Over', 'UgnZon4BransleFlodeAr_Under',\n",
       "       'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1',\n",
       "       'UgnZon4TempSkyddAr_TC2', 'UgnZon4TempVaggAr_TC3',\n",
       "       'UgnZon4TempVaggAr_TC4', 'UgnZon5OljaFlodeAr_FT531',\n",
       "       'UgnZon5TempAr_TC1', 'UgnZon5TempSkyddAr_TC2', 'UgnZon5TempVaggAr_TC3',\n",
       "       'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1',\n",
       "       'UgnZon6TempSkyddAr_TC2', 'UgnZon6TempUtgValvAr_TC5',\n",
       "       'UgnZon6TempVaggAr_TC3'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2366756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon1 = dfall[['AvgTemp_ZON1_M', 'DateTime', 'UgnZon1BransleFlodeAr_Under', 'UgnZon1BransleFlodeAr_Over',\n",
    "                 'UgnZon1OljaFlodeAr_FT131', 'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
    "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac82281",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Create lag features for dfzon1\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon1_lag = dfzon1.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon1.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon1_lag[f\"{col}_lag1\"] = dfzon1_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon1_lag = dfzon1_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon1 = dfzon1_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755d1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon2 = dfall[['AvgTemp_ZON2_M', 'DateTime', 'UgnZon2BransleFlodeAr_Under', 'UgnZon2BransleFlodeAr_Over',\n",
    "                 'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1', 'UgnZon2TempSkyddAr_TC2',\n",
    "         'UgnZon2TempVaggOverBandAr_TC3', 'UgnZon2TempVaggUnderBandAr_TC4', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c59672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon2\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon2_lag = dfzon2.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon2.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon2_lag[f\"{col}_lag1\"] = dfzon2_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon2_lag = dfzon2_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon2 = dfzon2_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb46c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon3 = dfall[['AvgTemp_ZON3_M', 'DateTime', 'UgnZon3BransleFlodeAr_Under', 'UgnZon3BransleFlodeAr_Over',\n",
    "                    'UgnZon3OljaFlodeAr_FT331', 'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
    "        'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', \"UgnZon3Temp_TC5_Ar\",  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c0a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon3\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon3_lag = dfzon3.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon3.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon3_lag[f\"{col}_lag1\"] = dfzon3_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon3_lag = dfzon3_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon3 = dfzon3_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2874233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon4 = dfall[['AvgTemp_ZON4_M', 'DateTime', 'UgnZon4BransleFlodeAr_Under', 'UgnZon4BransleFlodeAr_Over',\n",
    "                    'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1', 'UgnZon4TempSkyddAr_TC2',\n",
    "        'UgnZon4TempVaggAr_TC3', 'UgnZon4TempVaggAr_TC4',  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b64f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon4\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon4_lag = dfzon4.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon4.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon4_lag[f\"{col}_lag1\"] = dfzon4_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon4_lag = dfzon4_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon4 = dfzon4_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cdc88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon5 = dfall[['AvgTemp_ZON5_M', 'DateTime',  \n",
    "                    'UgnZon5OljaFlodeAr_FT531', 'UgnZon5TempAr_TC1', 'UgnZon5TempSkyddAr_TC2',\n",
    "        'UgnZon5TempVaggAr_TC3', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04798c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon5\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon5_lag = dfzon5.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon5.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon5_lag[f\"{col}_lag1\"] = dfzon5_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon5_lag = dfzon5_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon5 = dfzon5_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfed1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon6 = dfall[['AvgTemp_ZON6_M', 'DateTime',\n",
    "                    'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1', 'UgnZon6TempSkyddAr_TC2',\n",
    "        'UgnZon6TempVaggAr_TC3', \"UgnZon6TempUtgValvAr_TC5\",  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1bf2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon6\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon6_lag = dfzon6.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon6.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon6_lag[f\"{col}_lag1\"] = dfzon6_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon6_lag = dfzon6_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon6 = dfzon6_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32eb8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dfzon1 and dfzon2 together for furnace1 df\n",
    "df_furnace1 = pd.concat([dfzon1, dfzon2], axis=1)\n",
    "# Furnace 2 = Zones 3, 4, 5, and 6\n",
    "df_furnace2 = pd.concat([dfzon3, dfzon4, dfzon5, dfzon6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3340e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_furnace1 = df_furnace1.loc[:,~df_furnace1.columns.duplicated()]\n",
    "df_furnace2 = df_furnace2.loc[:,~df_furnace2.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9784cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgTemp_ZON1_M', 'DateTime', 'UgnZon1BransleFlodeAr_Under',\n",
       "       'UgnZon1BransleFlodeAr_Over', 'UgnZon1OljaFlodeAr_FT131',\n",
       "       'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
       "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4',\n",
       "       'LineControlHastSverk4_1Act', 'AvgTemp_ZON1_M_lag1',\n",
       "       'UgnZon1BransleFlodeAr_Under_lag1', 'UgnZon1BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon1OljaFlodeAr_FT131_lag1', 'UgnZon1TempRegAr_TC1_lag1',\n",
       "       'UgnZon1TempSkyddAr_TC2_lag1', 'UgnZon1TempVaggOverBandAr_TC3_lag1',\n",
       "       'UgnZon1TempVaggUnderBandAr_TC4_lag1',\n",
       "       'LineControlHastSverk4_1Act_lag1', 'AvgTemp_ZON2_M',\n",
       "       'UgnZon2BransleFlodeAr_Under', 'UgnZon2BransleFlodeAr_Over',\n",
       "       'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1',\n",
       "       'UgnZon2TempSkyddAr_TC2', 'UgnZon2TempVaggOverBandAr_TC3',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4', 'AvgTemp_ZON2_M_lag1',\n",
       "       'UgnZon2BransleFlodeAr_Under_lag1', 'UgnZon2BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon2OljaFlodeAr_FT231_lag1', 'UgnZon2TempAr_TC1_lag1',\n",
       "       'UgnZon2TempSkyddAr_TC2_lag1', 'UgnZon2TempVaggOverBandAr_TC3_lag1',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4_lag1'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a02c945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgTemp_ZON3_M', 'DateTime', 'UgnZon3BransleFlodeAr_Under',\n",
       "       'UgnZon3BransleFlodeAr_Over', 'UgnZon3OljaFlodeAr_FT331',\n",
       "       'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
       "       'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', 'UgnZon3Temp_TC5_Ar',\n",
       "       'LineControlHastSverk4_1Act', 'AvgTemp_ZON3_M_lag1',\n",
       "       'UgnZon3BransleFlodeAr_Under_lag1', 'UgnZon3BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon3OljaFlodeAr_FT331_lag1', 'UgnZon3TempRegAr_TC1_lag1',\n",
       "       'UgnZon3TempSkyddAr_TC2_lag1', 'UgnZon3TempVaggAr_TC3_lag1',\n",
       "       'UgnZon3Temp_TC4_Ar_lag1', 'UgnZon3Temp_TC5_Ar_lag1',\n",
       "       'LineControlHastSverk4_1Act_lag1', 'AvgTemp_ZON4_M',\n",
       "       'UgnZon4BransleFlodeAr_Under', 'UgnZon4BransleFlodeAr_Over',\n",
       "       'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1',\n",
       "       'UgnZon4TempSkyddAr_TC2', 'UgnZon4TempVaggAr_TC3',\n",
       "       'UgnZon4TempVaggAr_TC4', 'AvgTemp_ZON4_M_lag1',\n",
       "       'UgnZon4BransleFlodeAr_Under_lag1', 'UgnZon4BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon4OljaFlodeAr_FT431_lag1', 'UgnZon4TempAr_TC1_lag1',\n",
       "       'UgnZon4TempSkyddAr_TC2_lag1', 'UgnZon4TempVaggAr_TC3_lag1',\n",
       "       'UgnZon4TempVaggAr_TC4_lag1', 'AvgTemp_ZON5_M',\n",
       "       'UgnZon5OljaFlodeAr_FT531', 'UgnZon5TempAr_TC1',\n",
       "       'UgnZon5TempSkyddAr_TC2', 'UgnZon5TempVaggAr_TC3',\n",
       "       'AvgTemp_ZON5_M_lag1', 'UgnZon5OljaFlodeAr_FT531_lag1',\n",
       "       'UgnZon5TempAr_TC1_lag1', 'UgnZon5TempSkyddAr_TC2_lag1',\n",
       "       'UgnZon5TempVaggAr_TC3_lag1', 'AvgTemp_ZON6_M',\n",
       "       'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1',\n",
       "       'UgnZon6TempSkyddAr_TC2', 'UgnZon6TempVaggAr_TC3',\n",
       "       'UgnZon6TempUtgValvAr_TC5', 'AvgTemp_ZON6_M_lag1',\n",
       "       'UgnZon6OljaFlodeAr_FT631_lag1', 'UgnZon6TempAr_TC1_lag1',\n",
       "       'UgnZon6TempSkyddAr_TC2_lag1', 'UgnZon6TempVaggAr_TC3_lag1',\n",
       "       'UgnZon6TempUtgValvAr_TC5_lag1'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1006530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207295, 59)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Benchmark Evaluation ---\n",
      "\n",
      "--- Processing: furnace1 ---\n",
      "✅ Successfully processed furnace1. Correlation: 0.56. Plot saved to benchmark_plots\\benchmark_furnace1.png\n",
      "\n",
      "--- Processing: furnace2 ---\n",
      "✅ Successfully processed furnace2. Correlation: 0.44. Plot saved to benchmark_plots\\benchmark_furnace2.png\n",
      "\n",
      "--- Processing: zone1 ---\n",
      "✅ Successfully processed zone1. Correlation: 0.13. Plot saved to benchmark_plots\\benchmark_zone1.png\n",
      "\n",
      "--- Processing: zone2 ---\n",
      "✅ Successfully processed zone2. Correlation: 0.11. Plot saved to benchmark_plots\\benchmark_zone2.png\n",
      "\n",
      "--- Processing: zone3 ---\n",
      "✅ Successfully processed zone3. Correlation: 0.20. Plot saved to benchmark_plots\\benchmark_zone3.png\n",
      "\n",
      "--- Processing: zone4 ---\n",
      "✅ Successfully processed zone4. Correlation: 0.10. Plot saved to benchmark_plots\\benchmark_zone4.png\n",
      "\n",
      "--- Processing: zone5 ---\n",
      "✅ Successfully processed zone5. Correlation: 0.13. Plot saved to benchmark_plots\\benchmark_zone5.png\n",
      "\n",
      "--- Processing: zone6 ---\n",
      "✅ Successfully processed zone6. Correlation: 0.10. Plot saved to benchmark_plots\\benchmark_zone6.png\n",
      "\n",
      "--- Benchmark Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "AE_MODEL_DIR = \"zone_models_final\" # The folder with Autoencoder models\n",
    "IF_MODEL_DIR = \"zone_models_final_isoforest\" # The folder with Isolation Forest models\n",
    "PLOT_DIR = \"benchmark_plots\"\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "all_data_map = {\n",
    "    \"furnace1\": df_furnace1,\n",
    "    \"furnace2\": df_furnace2,\n",
    "    \"zone1\": dfzon1,\n",
    "    \"zone2\": dfzon2,\n",
    "    \"zone3\": dfzon3,\n",
    "    \"zone4\": dfzon4,\n",
    "    \"zone5\": dfzon5,\n",
    "    \"zone6\": dfzon6,\n",
    "}\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "print(\"--- Starting Benchmark Evaluation ---\")\n",
    "\n",
    "for name, df_full in all_data_map.items():\n",
    "    print(f\"\\n--- Processing: {name} ---\")\n",
    "    \n",
    "    # 1. Prepare Data: Drop non-numeric columns and handle NaNs\n",
    "    df_model = df_full.drop(columns=['DateTime']).dropna()\n",
    "    \n",
    "    if len(df_model) < 2:\n",
    "        print(f\"⚠️ Insufficient data for {name}. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    # 2. Recreate the Test Set\n",
    "    _, X_test_df = train_test_split(df_model, test_size=0.2, shuffle=False)\n",
    "\n",
    "    if X_test_df.empty:\n",
    "        print(f\"⚠️ Test set is empty for {name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 3. Load All Saved Models and Scalers\n",
    "    try:\n",
    "        ae_model = load_model(os.path.join(AE_MODEL_DIR, f\"{name}_autoencoder.keras\"))\n",
    "        ae_scaler = joblib.load(os.path.join(AE_MODEL_DIR, f\"{name}_scaler.pkl\"))\n",
    "        if_model = joblib.load(os.path.join(IF_MODEL_DIR, f\"{name}_isoforest.pkl\"))\n",
    "        if_scaler = joblib.load(os.path.join(IF_MODEL_DIR, f\"{name}_scaler_if.pkl\"))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ Error loading model files for {name}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4. Generate Anomaly Scores for the Test Set\n",
    "    # Autoencoder Scores\n",
    "    X_test_scaled_ae = ae_scaler.transform(X_test_df)\n",
    "    predictions_ae = ae_model.predict(X_test_scaled_ae, verbose=0)\n",
    "    scores_ae = np.mean(np.square(X_test_scaled_ae - predictions_ae), axis=1)\n",
    "\n",
    "    # Isolation Forest Scores\n",
    "    X_test_scaled_if = if_scaler.transform(X_test_df)\n",
    "    scores_if = -1 * if_model.score_samples(X_test_scaled_if)\n",
    "    \n",
    "    # 5. Normalize Scores to [0, 1] for Fair Comparison\n",
    "    if (scores_ae.max() - scores_ae.min()) > 0:\n",
    "        scores_ae_norm = (scores_ae - scores_ae.min()) / (scores_ae.max() - scores_ae.min())\n",
    "    else:\n",
    "        scores_ae_norm = np.zeros_like(scores_ae) \n",
    "\n",
    "    if (scores_if.max() - scores_if.min()) > 0:\n",
    "        scores_if_norm = (scores_if - scores_if.min()) / (scores_if.max() - scores_if.min())\n",
    "    else:\n",
    "        scores_if_norm = np.zeros_like(scores_if)\n",
    "        \n",
    "    # 6. Calculate Correlation\n",
    "    correlation = np.corrcoef(scores_ae_norm, scores_if_norm)[0, 1]\n",
    "    \n",
    "    # 7. Create and Save the Comparison Plot\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(scores_ae_norm, label='Autoencoder Score (Normalized)', color='blue', alpha=0.9)\n",
    "    plt.plot(scores_if_norm, label='Isolation Forest Score (Normalized)', color='red', alpha=0.7, linestyle='--')\n",
    "    plt.title(f'Benchmark Comparison for: {name}\\nCorrelation: {correlation:.2f}')\n",
    "    plt.xlabel('Time (Test Set Samples)')\n",
    "    plt.ylabel('Normalized Anomaly Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    plot_filename = os.path.join(PLOT_DIR, f\"benchmark_{name}.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close() \n",
    "\n",
    "    print(f\"✅ Successfully processed {name}. Correlation: {correlation:.2f}. Plot saved to {plot_filename}\")\n",
    "\n",
    "print(\"\\n--- Benchmark Evaluation Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
