{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd02fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32504dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.read_parquet('ThermocoupleData_2024-12_v2.parquet')\n",
    "df1 = pd.read_parquet('ThermocoupleData_2025-01_v2.parquet')\n",
    "df2 = pd.read_parquet('ThermocoupleData_2025-02_v2.parquet')\n",
    "df3 = pd.read_parquet('ThermocoupleData_2025-03_v2.parquet')\n",
    "df4 = pd.read_parquet('ThermocoupleData_2025-04_v2.parquet')\n",
    "\n",
    "dfall = pd.concat([df12, df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4ad2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df12: 44641\n",
      "df1: 44641\n",
      "df2: 40321\n",
      "df3: 44581\n",
      "df4: 33121\n",
      "dfall: 207305\n"
     ]
    }
   ],
   "source": [
    "# count of all the df rows\n",
    "print(f\"df12: {len(df12)}\")\n",
    "print(f\"df1: {len(df1)}\")\n",
    "print(f\"df2: {len(df2)}\")\n",
    "print(f\"df3: {len(df3)}\")\n",
    "print(f\"df4: {len(df4)}\")\n",
    "print(f\"dfall: {len(dfall)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f57b7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateTime', 'AvgTemp_ZON1_M', 'AvgTemp_ZON2_M', 'AvgTemp_ZON3_M',\n",
       "       'AvgTemp_ZON4_M', 'AvgTemp_ZON5_M', 'AvgTemp_ZON6_M',\n",
       "       'LineControlHastSverk4_1Act', 'UgnZon1BransleFlodeAr_Over',\n",
       "       'UgnZon1BransleFlodeAr_Under', 'UgnZon1OljaFlodeAr_FT131',\n",
       "       'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
       "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4',\n",
       "       'UgnZon2BransleFlodeAr_Over', 'UgnZon2BransleFlodeAr_Under',\n",
       "       'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1',\n",
       "       'UgnZon2TempSkyddAr_TC2', 'UgnZon2TempVaggOverBandAr_TC3',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4', 'UgnZon3BransleFlodeAr_Over',\n",
       "       'UgnZon3BransleFlodeAr_Under', 'UgnZon3OljaFlodeAr_FT331',\n",
       "       'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
       "       'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', 'UgnZon3Temp_TC5_Ar',\n",
       "       'UgnZon4BransleFlodeAr_Over', 'UgnZon4BransleFlodeAr_Under',\n",
       "       'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1',\n",
       "       'UgnZon4TempSkyddAr_TC2', 'UgnZon4TempVaggAr_TC3',\n",
       "       'UgnZon4TempVaggAr_TC4', 'UgnZon5OljaFlodeAr_FT531',\n",
       "       'UgnZon5TempAr_TC1', 'UgnZon5TempSkyddAr_TC2', 'UgnZon5TempVaggAr_TC3',\n",
       "       'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1',\n",
       "       'UgnZon6TempSkyddAr_TC2', 'UgnZon6TempUtgValvAr_TC5',\n",
       "       'UgnZon6TempVaggAr_TC3'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4788cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon1 = dfall[['AvgTemp_ZON1_M', 'DateTime', 'UgnZon1BransleFlodeAr_Under', 'UgnZon1BransleFlodeAr_Over',\n",
    "                 'UgnZon1OljaFlodeAr_FT131', 'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
    "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48f055",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (207295, 19), New shape with lag features: (207305, 19)\n"
     ]
    }
   ],
   "source": [
    "# Create lag features for dfzon1\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon1_lag = dfzon1.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon1.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon1_lag[f\"{col}_lag1\"] = dfzon1_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon1_lag = dfzon1_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon1 = dfzon1_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2536ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon2 = dfall[['AvgTemp_ZON2_M', 'DateTime', 'UgnZon2BransleFlodeAr_Under', 'UgnZon2BransleFlodeAr_Over',\n",
    "                 'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1', 'UgnZon2TempSkyddAr_TC2',\n",
    "         'UgnZon2TempVaggOverBandAr_TC3', 'UgnZon2TempVaggUnderBandAr_TC4', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5e87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon2\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon2_lag = dfzon2.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon2.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon2_lag[f\"{col}_lag1\"] = dfzon2_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon2_lag = dfzon2_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon2 = dfzon2_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a57bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon3 = dfall[['AvgTemp_ZON3_M', 'DateTime', 'UgnZon3BransleFlodeAr_Under', 'UgnZon3BransleFlodeAr_Over',\n",
    "                    'UgnZon3OljaFlodeAr_FT331', 'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
    "        'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', \"UgnZon3Temp_TC5_Ar\",  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "510506bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon3\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon3_lag = dfzon3.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon3.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon3_lag[f\"{col}_lag1\"] = dfzon3_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon3_lag = dfzon3_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon3 = dfzon3_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a7432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon4 = dfall[['AvgTemp_ZON4_M', 'DateTime', 'UgnZon4BransleFlodeAr_Under', 'UgnZon4BransleFlodeAr_Over',\n",
    "                    'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1', 'UgnZon4TempSkyddAr_TC2',\n",
    "        'UgnZon4TempVaggAr_TC3', 'UgnZon4TempVaggAr_TC4',  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7517b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon4\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon4_lag = dfzon4.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon4.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon4_lag[f\"{col}_lag1\"] = dfzon4_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon4_lag = dfzon4_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon4 = dfzon4_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbbd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon5 = dfall[['AvgTemp_ZON5_M', 'DateTime',  \n",
    "                    'UgnZon5OljaFlodeAr_FT531', 'UgnZon5TempAr_TC1', 'UgnZon5TempSkyddAr_TC2',\n",
    "        'UgnZon5TempVaggAr_TC3', 'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6a739d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon5\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon5_lag = dfzon5.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon5.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon5_lag[f\"{col}_lag1\"] = dfzon5_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon5_lag = dfzon5_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon5 = dfzon5_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7990612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzon6 = dfall[['AvgTemp_ZON6_M', 'DateTime',\n",
    "                    'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1', 'UgnZon6TempSkyddAr_TC2',\n",
    "        'UgnZon6TempVaggAr_TC3', \"UgnZon6TempUtgValvAr_TC5\",  'LineControlHastSverk4_1Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f90bae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for dfzon6\n",
    "# First, ensure the dataframe is sorted by DateTime\n",
    "dfzon6_lag = dfzon6.sort_values('DateTime').copy()\n",
    "\n",
    "# List of columns to create lag features for (all columns except DateTime)\n",
    "columns_to_lag = [col for col in dfzon6.columns if col != 'DateTime']\n",
    "\n",
    "# Create lag1 features for each column\n",
    "for col in columns_to_lag:\n",
    "    dfzon6_lag[f\"{col}_lag1\"] = dfzon6_lag[col].shift(1)\n",
    "\n",
    "# Reset index\n",
    "dfzon6_lag = dfzon6_lag.reset_index(drop=True)\n",
    "\n",
    "# Note: The first row will have NaN values for all lag columns\n",
    "# Drop the first row with NaN values if needed\n",
    "dfzon6 = dfzon6_lag.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf9a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dfzon1 and dfzon2 together for furnace1 df\n",
    "df_furnace1 = pd.concat([dfzon1, dfzon2], axis=1)\n",
    "# Furnace 2 = Zones 3, 4, 5, and 6\n",
    "df_furnace2 = pd.concat([dfzon3, dfzon4, dfzon5, dfzon6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "316c8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_furnace1 = df_furnace1.loc[:,~df_furnace1.columns.duplicated()]\n",
    "df_furnace2 = df_furnace2.loc[:,~df_furnace2.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5981a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgTemp_ZON1_M', 'DateTime', 'UgnZon1BransleFlodeAr_Under',\n",
       "       'UgnZon1BransleFlodeAr_Over', 'UgnZon1OljaFlodeAr_FT131',\n",
       "       'UgnZon1TempRegAr_TC1', 'UgnZon1TempSkyddAr_TC2',\n",
       "       'UgnZon1TempVaggOverBandAr_TC3', 'UgnZon1TempVaggUnderBandAr_TC4',\n",
       "       'LineControlHastSverk4_1Act', 'AvgTemp_ZON1_M_lag1',\n",
       "       'UgnZon1BransleFlodeAr_Under_lag1', 'UgnZon1BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon1OljaFlodeAr_FT131_lag1', 'UgnZon1TempRegAr_TC1_lag1',\n",
       "       'UgnZon1TempSkyddAr_TC2_lag1', 'UgnZon1TempVaggOverBandAr_TC3_lag1',\n",
       "       'UgnZon1TempVaggUnderBandAr_TC4_lag1',\n",
       "       'LineControlHastSverk4_1Act_lag1', 'AvgTemp_ZON2_M',\n",
       "       'UgnZon2BransleFlodeAr_Under', 'UgnZon2BransleFlodeAr_Over',\n",
       "       'UgnZon2OljaFlodeAr_FT231', 'UgnZon2TempAr_TC1',\n",
       "       'UgnZon2TempSkyddAr_TC2', 'UgnZon2TempVaggOverBandAr_TC3',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4', 'AvgTemp_ZON2_M_lag1',\n",
       "       'UgnZon2BransleFlodeAr_Under_lag1', 'UgnZon2BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon2OljaFlodeAr_FT231_lag1', 'UgnZon2TempAr_TC1_lag1',\n",
       "       'UgnZon2TempSkyddAr_TC2_lag1', 'UgnZon2TempVaggOverBandAr_TC3_lag1',\n",
       "       'UgnZon2TempVaggUnderBandAr_TC4_lag1'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92400f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgTemp_ZON3_M', 'DateTime', 'UgnZon3BransleFlodeAr_Under',\n",
       "       'UgnZon3BransleFlodeAr_Over', 'UgnZon3OljaFlodeAr_FT331',\n",
       "       'UgnZon3TempRegAr_TC1', 'UgnZon3TempSkyddAr_TC2',\n",
       "       'UgnZon3TempVaggAr_TC3', 'UgnZon3Temp_TC4_Ar', 'UgnZon3Temp_TC5_Ar',\n",
       "       'LineControlHastSverk4_1Act', 'AvgTemp_ZON3_M_lag1',\n",
       "       'UgnZon3BransleFlodeAr_Under_lag1', 'UgnZon3BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon3OljaFlodeAr_FT331_lag1', 'UgnZon3TempRegAr_TC1_lag1',\n",
       "       'UgnZon3TempSkyddAr_TC2_lag1', 'UgnZon3TempVaggAr_TC3_lag1',\n",
       "       'UgnZon3Temp_TC4_Ar_lag1', 'UgnZon3Temp_TC5_Ar_lag1',\n",
       "       'LineControlHastSverk4_1Act_lag1', 'AvgTemp_ZON4_M',\n",
       "       'UgnZon4BransleFlodeAr_Under', 'UgnZon4BransleFlodeAr_Over',\n",
       "       'UgnZon4OljaFlodeAr_FT431', 'UgnZon4TempAr_TC1',\n",
       "       'UgnZon4TempSkyddAr_TC2', 'UgnZon4TempVaggAr_TC3',\n",
       "       'UgnZon4TempVaggAr_TC4', 'AvgTemp_ZON4_M_lag1',\n",
       "       'UgnZon4BransleFlodeAr_Under_lag1', 'UgnZon4BransleFlodeAr_Over_lag1',\n",
       "       'UgnZon4OljaFlodeAr_FT431_lag1', 'UgnZon4TempAr_TC1_lag1',\n",
       "       'UgnZon4TempSkyddAr_TC2_lag1', 'UgnZon4TempVaggAr_TC3_lag1',\n",
       "       'UgnZon4TempVaggAr_TC4_lag1', 'AvgTemp_ZON5_M',\n",
       "       'UgnZon5OljaFlodeAr_FT531', 'UgnZon5TempAr_TC1',\n",
       "       'UgnZon5TempSkyddAr_TC2', 'UgnZon5TempVaggAr_TC3',\n",
       "       'AvgTemp_ZON5_M_lag1', 'UgnZon5OljaFlodeAr_FT531_lag1',\n",
       "       'UgnZon5TempAr_TC1_lag1', 'UgnZon5TempSkyddAr_TC2_lag1',\n",
       "       'UgnZon5TempVaggAr_TC3_lag1', 'AvgTemp_ZON6_M',\n",
       "       'UgnZon6OljaFlodeAr_FT631', 'UgnZon6TempAr_TC1',\n",
       "       'UgnZon6TempSkyddAr_TC2', 'UgnZon6TempVaggAr_TC3',\n",
       "       'UgnZon6TempUtgValvAr_TC5', 'AvgTemp_ZON6_M_lag1',\n",
       "       'UgnZon6OljaFlodeAr_FT631_lag1', 'UgnZon6TempAr_TC1_lag1',\n",
       "       'UgnZon6TempSkyddAr_TC2_lag1', 'UgnZon6TempVaggAr_TC3_lag1',\n",
       "       'UgnZon6TempUtgValvAr_TC5_lag1'],\n",
       "      dtype='object', name='TagName')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "282bf629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207295, 59)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_furnace2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf # For seed setting if desired\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_autoencoder(df_zone, zone_name, model_dir=\"zone_models_final\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Drop DateTime and rows with NaN\n",
    "    df_model = df_zone.drop(columns=['DateTime']).dropna()\n",
    "\n",
    "    if df_model.empty or len(df_model) < 2: \n",
    "        print(f\"⚠️ Insufficient data for {zone_name} after dropping NaNs (rows: {len(df_model)}). Skipping training.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    test_s = 0.2\n",
    "    if int(len(df_model) * test_s) == 0 and len(df_model) > 1: \n",
    "        if len(df_model) > 5: \n",
    "            test_s = 1 / len(df_model)\n",
    "        else: \n",
    "            print(f\"⚠️ Very few samples for {zone_name} ({len(df_model)}), cannot reliably split. Skipping.\")\n",
    "            return\n",
    "\n",
    "\n",
    "    # shuffle=False is crucial for time-series data to prevent future data from leaking into the training set.\n",
    "    X_train_df, X_test_df = train_test_split(df_model, test_size=test_s, shuffle=False)\n",
    "\n",
    "    if X_train_df.empty or X_test_df.empty:\n",
    "        print(f\"⚠️ Not enough data for {zone_name} after train/test split (Train: {len(X_train_df)}, Test: {len(X_test_df)}). Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_df) # Fit ONLY on training data\n",
    "    X_test = scaler.transform(X_test_df)     # Transform test data\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    if input_dim == 0:\n",
    "        print(f\"⚠️ No features remaining for {zone_name} after scaling. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Define simple autoencoder\n",
    "    autoencoder = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(max(4, int(input_dim * 0.75)), activation='relu'), \n",
    "        layers.Dense(max(2, int(input_dim * 0.5)), activation='relu'),  \n",
    "        layers.Dense(max(4, int(input_dim * 0.75)), activation='relu'),\n",
    "        layers.Dense(input_dim, activation='linear')\n",
    "    ])\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train\n",
    "    history = autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50, \n",
    "        batch_size=32, \n",
    "        validation_data=(X_test, X_test),\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)], \n",
    "        verbose=0 \n",
    "    )\n",
    "\n",
    "    # Predict and calculate MSE\n",
    "    X_test_pred = autoencoder.predict(X_test)\n",
    "    mse = np.mean(np.square(X_test - X_test_pred), axis=1)\n",
    "\n",
    "    if len(mse) == 0:\n",
    "        print(f\"⚠️ MSE calculation resulted in empty array for {zone_name}. Skipping threshold and saving.\")\n",
    "        return\n",
    "\n",
    "    threshold = np.percentile(mse, 95) # Or 99, etc, as mentioned in the thesis report, this can be modified based on needs.\n",
    "\n",
    "    # Save model, scaler, threshold\n",
    "    model_path = os.path.join(model_dir, f\"{zone_name}_autoencoder.keras\")\n",
    "    scaler_path = os.path.join(model_dir, f\"{zone_name}_scaler.pkl\")\n",
    "    threshold_path = os.path.join(model_dir, f\"{zone_name}_threshold.npy\")\n",
    "\n",
    "    try:\n",
    "        autoencoder.save(model_path)\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        np.save(threshold_path, threshold)\n",
    "        print(f\"✅ Trained and saved model for {zone_name} | Threshold: {threshold:.4f} | Train Loss: {history.history['loss'][-1]:.4f} | Val Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving artifacts for {zone_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c15bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step\n",
      "✅ Trained and saved model for zone1 | Threshold: 0.0077 | Train Loss: 0.0016 | Val Loss: 0.0024\n",
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step\n",
      "✅ Trained and saved model for zone2 | Threshold: 0.0099 | Train Loss: 0.0025 | Val Loss: 0.0034\n",
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step\n",
      "✅ Trained and saved model for zone3 | Threshold: 0.0178 | Train Loss: 0.0012 | Val Loss: 0.0043\n",
      "\u001b[1m1227/1227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step\n",
      "✅ Trained and saved model for zone4 | Threshold: 0.0092 | Train Loss: 0.0008 | Val Loss: 0.0020\n",
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step\n",
      "✅ Trained and saved model for zone5 | Threshold: 0.0333 | Train Loss: 0.0060 | Val Loss: 0.0101\n",
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step\n",
      "✅ Trained and saved model for zone6 | Threshold: 0.0105 | Train Loss: 0.0023 | Val Loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "train_autoencoder(dfzon1, \"zone1\")\n",
    "train_autoencoder(dfzon2, \"zone2\")\n",
    "train_autoencoder(dfzon3, \"zone3\")\n",
    "train_autoencoder(dfzon4, \"zone4\")\n",
    "train_autoencoder(dfzon5, \"zone5\")\n",
    "train_autoencoder(dfzon6, \"zone6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0498624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step\n",
      "✅ Trained and saved model for furnace1 | Threshold: 0.0127 | Train Loss: 0.0015 | Val Loss: 0.0032\n",
      "\u001b[1m1227/1227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step\n",
      "✅ Trained and saved model for furnace2 | Threshold: 0.0143 | Train Loss: 0.0013 | Val Loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "train_autoencoder(df_furnace1, \"furnace1\")\n",
    "train_autoencoder(df_furnace2, \"furnace2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_isolation_forest(df_zone, zone_name, model_dir=\"zone_models_final_isoforest\"):\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Preprocessing: Drop DateTime and rows with NaN \n",
    "    df_model = df_zone.drop(columns=['DateTime']).dropna()\n",
    "\n",
    "    if df_model.empty or len(df_model) < 2:\n",
    "        print(f\"⚠️ [IF] Insufficient data for {zone_name} after dropping NaNs (rows: {len(df_model)}). Skipping training.\")\n",
    "        return\n",
    "\n",
    "    # 2. Train/Test Split: Crucially, shuffle=False for time-series data\n",
    "    # Use the same test_size to ensure the split is comparable to the autoencoder's.\n",
    "    X_train_df, X_test_df = train_test_split(df_model, test_size=0.2, shuffle=False)\n",
    "\n",
    "    if X_train_df.empty or X_test_df.empty:\n",
    "        print(f\"⚠️ [IF] Not enough data for {zone_name} after train/test split. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 3. Scaling: Fit on train, transform both train and test\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_df)\n",
    "    X_test = scaler.transform(X_test_df)\n",
    "\n",
    "    # 4. Model Definition and Training\n",
    "    iso_forest = IsolationForest(contamination='auto', random_state=42, n_jobs=-1) # n_jobs=-1 uses all CPU cores\n",
    "    \n",
    "    iso_forest.fit(X_train)\n",
    "\n",
    "    # 5. Calculate Anomaly Scores on the Test Set\n",
    "    # A higher score will now mean MORE anomalous, just like reconstruction error.\n",
    "    anomaly_scores = -1 * iso_forest.score_samples(X_test)\n",
    "\n",
    "    if len(anomaly_scores) == 0:\n",
    "        print(f\"⚠️ [IF] Score calculation resulted in empty array for {zone_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 6. Determine the 95th Percentile Threshold\n",
    "    # This threshold is same as AE threshold. again, this is just a placeholder and can be adjusted.\n",
    "    threshold = np.percentile(anomaly_scores, 95)\n",
    "\n",
    "    # 7. Save \n",
    "    model_path: str = os.path.join(model_dir, f\"{zone_name}_isoforest.pkl\")\n",
    "    scaler_path = os.path.join(model_dir, f\"{zone_name}_scaler_if.pkl\") \n",
    "    threshold_path = os.path.join(model_dir, f\"{zone_name}_threshold_if.npy\")\n",
    "\n",
    "    try:\n",
    "        joblib.dump(iso_forest, model_path)\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        np.save(threshold_path, threshold)\n",
    "        print(f\"✅ [IF] Trained and saved model for {zone_name} | Threshold: {threshold:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ [IF] Error saving artifacts for {zone_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "946d9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [IF] Trained and saved model for zone1 | Threshold: 0.6172\n",
      "✅ [IF] Trained and saved model for zone2 | Threshold: 0.6583\n",
      "✅ [IF] Trained and saved model for zone3 | Threshold: 0.6491\n",
      "✅ [IF] Trained and saved model for zone4 | Threshold: 0.6418\n",
      "✅ [IF] Trained and saved model for zone5 | Threshold: 0.6987\n",
      "✅ [IF] Trained and saved model for zone6 | Threshold: 0.6986\n",
      "✅ [IF] Trained and saved model for furnace1 | Threshold: 0.6130\n",
      "✅ [IF] Trained and saved model for furnace2 | Threshold: 0.6399\n"
     ]
    }
   ],
   "source": [
    "train_isolation_forest(dfzon1, \"zone1\")\n",
    "train_isolation_forest(dfzon2, \"zone2\")\n",
    "train_isolation_forest(dfzon3, \"zone3\")\n",
    "train_isolation_forest(dfzon4, \"zone4\")\n",
    "train_isolation_forest(dfzon5, \"zone5\")\n",
    "train_isolation_forest(dfzon6, \"zone6\")\n",
    "train_isolation_forest(df_furnace1, \"furnace1\")\n",
    "train_isolation_forest(df_furnace2, \"furnace2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_thermocouple_regressor(df_zone_original, target_thermocouple_col, zone_name, model_type='ridge', model_dir=\"tc_regression_models_final_withlag\"):\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    print(f\"\\n--- Training regressor for {target_thermocouple_col} in {zone_name} (Model: {model_type}) ---\")\n",
    "\n",
    "    df_zone = df_zone_original.copy()\n",
    "\n",
    "    # 1. Prepare Data\n",
    "    if target_thermocouple_col not in df_zone.columns:\n",
    "        print(f\"❌ Target column '{target_thermocouple_col}' not found in DataFrame for {zone_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Drop DateTime and any rows with NaNs\n",
    "    df_model = df_zone.drop(columns=['DateTime']).dropna(subset=[target_thermocouple_col]) \n",
    "    df_model = df_model.dropna() \n",
    "\n",
    "    if df_model.empty or len(df_model) < 2:\n",
    "        print(f\"⚠️ Insufficient data for {target_thermocouple_col} in {zone_name} after cleaning (rows: {len(df_model)}). Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    y = df_model[target_thermocouple_col]\n",
    "    X = df_model.drop(columns=[target_thermocouple_col])\n",
    "\n",
    "    if X.empty:\n",
    "        print(f\"⚠️ No features remaining for {target_thermocouple_col} in {zone_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 2. Train/Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "    print(f\"  ➤ Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"  ➤ Testing samples:  {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "    if X_train.empty or X_test.empty:\n",
    "        print(f\"⚠️ Not enough data for train/test split for {target_thermocouple_col} in {zone_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 3. Scale Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 4. Initialize and Train Model\n",
    "    if model_type.lower() == 'ridge':\n",
    "        model = Ridge(alpha=1.0)  # Alpha is the regularization strength, can be tuned\n",
    "    elif model_type.lower() == 'lasso':\n",
    "        model = Lasso(alpha=0.1) # Alpha for Lasso, can be tuned, lasso was not used in the final report!\n",
    "    else:\n",
    "        print(f\"❌ Invalid model_type: {model_type}. Choose 'ridge' or 'lasso'. Skipping.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training model for {target_thermocouple_col} in {zone_name}: {e}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 5. Evaluate Model\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"Evaluation for {target_thermocouple_col}:\")\n",
    "    print(f\"  Train MSE: {train_mse:.4f}, R2: {train_r2:.4f}\")\n",
    "    print(f\"  Test MSE:  {test_mse:.4f}, R2: {test_r2:.4f}\")\n",
    "\n",
    "    # 6. Save Model and Scaler\n",
    "    safe_target_name = target_thermocouple_col.replace('/', '_').replace('\\\\', '_')\n",
    "    model_filename = f\"{zone_name}_{safe_target_name}_{model_type}_regressor.pkl\"\n",
    "    scaler_filename = f\"{zone_name}_{safe_target_name}_{model_type}_scaler.pkl\"\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    scaler_path = os.path.join(model_dir, scaler_filename)\n",
    "\n",
    "    try:\n",
    "        joblib.dump(model, model_path)\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        print(f\"✅ Saved model to {model_path}\")\n",
    "        print(f\"✅ Saved scaler to {scaler_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving artifacts for {target_thermocouple_col} in {zone_name}: {e}\")\n",
    "\n",
    "    return model, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6251e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training regressor for UgnZon1TempRegAr_TC1 in ZON1 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon1TempRegAr_TC1:\n",
      "  Train MSE: 16.3865, R2: 0.9995\n",
      "  Test MSE:  8.5935, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON1_UgnZon1TempRegAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON1_UgnZon1TempRegAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon1TempSkyddAr_TC2 in ZON1 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon1TempSkyddAr_TC2:\n",
      "  Train MSE: 12.6057, R2: 0.9996\n",
      "  Test MSE:  7.3865, R2: 0.9999\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON1_UgnZon1TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON1_UgnZon1TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon1TempVaggOverBandAr_TC3 in ZON1 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon1TempVaggOverBandAr_TC3:\n",
      "  Train MSE: 57.0481, R2: 0.9981\n",
      "  Test MSE:  34.1680, R2: 0.9992\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON1_UgnZon1TempVaggOverBandAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON1_UgnZon1TempVaggOverBandAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon1TempVaggUnderBandAr_TC4 in ZON1 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon1TempVaggUnderBandAr_TC4:\n",
      "  Train MSE: 25.1136, R2: 0.9990\n",
      "  Test MSE:  13.4332, R2: 0.9997\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON1_UgnZon1TempVaggUnderBandAr_TC4_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON1_UgnZon1TempVaggUnderBandAr_TC4_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon2TempAr_TC1 in ZON2 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon2TempAr_TC1:\n",
      "  Train MSE: 14.9375, R2: 0.9993\n",
      "  Test MSE:  7.8061, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON2_UgnZon2TempAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON2_UgnZon2TempAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon2TempSkyddAr_TC2 in ZON2 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon2TempSkyddAr_TC2:\n",
      "  Train MSE: 10.4604, R2: 0.9996\n",
      "  Test MSE:  8.1981, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON2_UgnZon2TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON2_UgnZon2TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon2TempVaggOverBandAr_TC3 in ZON2 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon2TempVaggOverBandAr_TC3:\n",
      "  Train MSE: 37.3627, R2: 0.9988\n",
      "  Test MSE:  17.3064, R2: 0.9997\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON2_UgnZon2TempVaggOverBandAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON2_UgnZon2TempVaggOverBandAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon2TempVaggUnderBandAr_TC4 in ZON2 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon2TempVaggUnderBandAr_TC4:\n",
      "  Train MSE: 30.2815, R2: 0.9989\n",
      "  Test MSE:  26.1013, R2: 0.9995\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON2_UgnZon2TempVaggUnderBandAr_TC4_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON2_UgnZon2TempVaggUnderBandAr_TC4_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon3TempRegAr_TC1 in ZON3 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon3TempRegAr_TC1:\n",
      "  Train MSE: 13.7344, R2: 0.9996\n",
      "  Test MSE:  7.7554, R2: 0.9999\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON3_UgnZon3TempRegAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON3_UgnZon3TempRegAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon3TempSkyddAr_TC2 in ZON3 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon3TempSkyddAr_TC2:\n",
      "  Train MSE: 17.7539, R2: 0.9995\n",
      "  Test MSE:  11.4640, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON3_UgnZon3TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON3_UgnZon3TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon3TempVaggAr_TC3 in ZON3 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon3TempVaggAr_TC3:\n",
      "  Train MSE: 32.3733, R2: 0.9994\n",
      "  Test MSE:  19.1405, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON3_UgnZon3TempVaggAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON3_UgnZon3TempVaggAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon3Temp_TC4_Ar in ZON3 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon3Temp_TC4_Ar:\n",
      "  Train MSE: 55.2823, R2: 0.9988\n",
      "  Test MSE:  23.4380, R2: 0.9997\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON3_UgnZon3Temp_TC4_Ar_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON3_UgnZon3Temp_TC4_Ar_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon3Temp_TC5_Ar in ZON3 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon3Temp_TC5_Ar:\n",
      "  Train MSE: 22.7540, R2: 0.9994\n",
      "  Test MSE:  18.5426, R2: 0.9997\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON3_UgnZon3Temp_TC5_Ar_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON3_UgnZon3Temp_TC5_Ar_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon4TempAr_TC1 in ZON4 (Model: ridge) ---\n",
      "  ➤ Training samples: 157037\n",
      "  ➤ Testing samples:  39260\n",
      "Evaluation for UgnZon4TempAr_TC1:\n",
      "  Train MSE: 45.4492, R2: 0.9988\n",
      "  Test MSE:  9.7767, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON4_UgnZon4TempAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON4_UgnZon4TempAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon4TempSkyddAr_TC2 in ZON4 (Model: ridge) ---\n",
      "  ➤ Training samples: 157037\n",
      "  ➤ Testing samples:  39260\n",
      "Evaluation for UgnZon4TempSkyddAr_TC2:\n",
      "  Train MSE: 30.7296, R2: 0.9991\n",
      "  Test MSE:  9.0770, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON4_UgnZon4TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON4_UgnZon4TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon4TempVaggAr_TC3 in ZON4 (Model: ridge) ---\n",
      "  ➤ Training samples: 157037\n",
      "  ➤ Testing samples:  39260\n",
      "Evaluation for UgnZon4TempVaggAr_TC3:\n",
      "  Train MSE: 23.4345, R2: 0.9995\n",
      "  Test MSE:  25.5134, R2: 0.9996\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON4_UgnZon4TempVaggAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON4_UgnZon4TempVaggAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon4TempVaggAr_TC4 in ZON4 (Model: ridge) ---\n",
      "  ➤ Training samples: 157037\n",
      "  ➤ Testing samples:  39260\n",
      "Evaluation for UgnZon4TempVaggAr_TC4:\n",
      "  Train MSE: 0.0000, R2: 1.0000\n",
      "  Test MSE:  0.0000, R2: 1.0000\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON4_UgnZon4TempVaggAr_TC4_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON4_UgnZon4TempVaggAr_TC4_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon5TempAr_TC1 in ZON5 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon5TempAr_TC1:\n",
      "  Train MSE: 8.0401, R2: 0.9998\n",
      "  Test MSE:  3.0098, R2: 0.9999\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON5_UgnZon5TempAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON5_UgnZon5TempAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon5TempSkyddAr_TC2 in ZON5 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon5TempSkyddAr_TC2:\n",
      "  Train MSE: 6.2789, R2: 0.9998\n",
      "  Test MSE:  2.7858, R2: 1.0000\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON5_UgnZon5TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON5_UgnZon5TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon5TempVaggAr_TC3 in ZON5 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon5TempVaggAr_TC3:\n",
      "  Train MSE: 31.3187, R2: 0.9992\n",
      "  Test MSE:  37.0516, R2: 0.9996\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON5_UgnZon5TempVaggAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON5_UgnZon5TempVaggAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon6TempAr_TC1 in ZON6 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon6TempAr_TC1:\n",
      "  Train MSE: 2.9361, R2: 0.9999\n",
      "  Test MSE:  2.0461, R2: 1.0000\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON6_UgnZon6TempAr_TC1_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON6_UgnZon6TempAr_TC1_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon6TempSkyddAr_TC2 in ZON6 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon6TempSkyddAr_TC2:\n",
      "  Train MSE: 2.5225, R2: 0.9999\n",
      "  Test MSE:  1.4848, R2: 1.0000\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON6_UgnZon6TempSkyddAr_TC2_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON6_UgnZon6TempSkyddAr_TC2_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon6TempVaggAr_TC3 in ZON6 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon6TempVaggAr_TC3:\n",
      "  Train MSE: 12.3943, R2: 0.9997\n",
      "  Test MSE:  17.7978, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON6_UgnZon6TempVaggAr_TC3_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON6_UgnZon6TempVaggAr_TC3_ridge_scaler.pkl\n",
      "\n",
      "--- Training regressor for UgnZon6TempUtgValvAr_TC5 in ZON6 (Model: ridge) ---\n",
      "  ➤ Training samples: 165836\n",
      "  ➤ Testing samples:  41459\n",
      "Evaluation for UgnZon6TempUtgValvAr_TC5:\n",
      "  Train MSE: 46.5996, R2: 0.9986\n",
      "  Test MSE:  15.2231, R2: 0.9998\n",
      "✅ Saved model to tc_regression_models_final_withlag\\ZON6_UgnZon6TempUtgValvAr_TC5_ridge_regressor.pkl\n",
      "✅ Saved scaler to tc_regression_models_final_withlag\\ZON6_UgnZon6TempUtgValvAr_TC5_ridge_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define thermocouple columns per zone\n",
    "thermocouple_cols_by_zone = {\n",
    "    \"ZON1\": [\n",
    "        'UgnZon1TempRegAr_TC1',\n",
    "        'UgnZon1TempSkyddAr_TC2',\n",
    "        'UgnZon1TempVaggOverBandAr_TC3',\n",
    "        'UgnZon1TempVaggUnderBandAr_TC4'\n",
    "    ],\n",
    "    \"ZON2\": [\n",
    "        'UgnZon2TempAr_TC1',\n",
    "        'UgnZon2TempSkyddAr_TC2',\n",
    "        'UgnZon2TempVaggOverBandAr_TC3',\n",
    "        'UgnZon2TempVaggUnderBandAr_TC4'\n",
    "    ],\n",
    "    \"ZON3\": [\n",
    "        'UgnZon3TempRegAr_TC1',\n",
    "        'UgnZon3TempSkyddAr_TC2',\n",
    "        'UgnZon3TempVaggAr_TC3',\n",
    "        'UgnZon3Temp_TC4_Ar',\n",
    "        'UgnZon3Temp_TC5_Ar'\n",
    "    ],\n",
    "    \"ZON4\": [\n",
    "        'UgnZon4TempAr_TC1',\n",
    "        'UgnZon4TempSkyddAr_TC2',\n",
    "        'UgnZon4TempVaggAr_TC3',\n",
    "        'UgnZon4TempVaggAr_TC4'\n",
    "    ],\n",
    "    \"ZON5\": [\n",
    "        'UgnZon5TempAr_TC1',\n",
    "        'UgnZon5TempSkyddAr_TC2',\n",
    "        'UgnZon5TempVaggAr_TC3'\n",
    "    ],\n",
    "    \"ZON6\": [\n",
    "        'UgnZon6TempAr_TC1',\n",
    "        'UgnZon6TempSkyddAr_TC2',\n",
    "        'UgnZon6TempVaggAr_TC3',\n",
    "        'UgnZon6TempUtgValvAr_TC5'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define the dataframes per zone\n",
    "df_by_zone = {\n",
    "    \"ZON1\": dfzon1,\n",
    "    \"ZON2\": dfzon2,\n",
    "    \"ZON3\": dfzon3,\n",
    "    \"ZON4\": dfzon4,\n",
    "    \"ZON5\": dfzon5,\n",
    "    \"ZON6\": dfzon6\n",
    "}\n",
    "\n",
    "# Train the regressors for each thermocouple in each zone\n",
    "for zone, tc_cols in thermocouple_cols_by_zone.items():\n",
    "    df = df_by_zone[zone]\n",
    "    for tc_col in tc_cols:\n",
    "        train_thermocouple_regressor(df, tc_col, zone, model_type='ridge')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
